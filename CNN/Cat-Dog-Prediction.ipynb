{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Q0bYPApFqsL3fe66bUouM2MmASV8We6w",
      "authorship_tag": "ABX9TyPhULO513rpRBpanDvo/Y+X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudharshanpaul/Deep-Learning/blob/main/CNN/Cat-Dog-Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW2P3MDro0P2",
        "outputId": "88636b7f-72a8-4721-8798-c0bfd96d12e4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Neural Network"
      ],
      "metadata": {
        "id": "XeSV_5NSLr66"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing Libraries"
      ],
      "metadata": {
        "id": "NY2z11nbLv1M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "MTIoVj3qSAtw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "irG-VPx4MxzQ",
        "outputId": "c7dbbab1-ec1a-4f8b-8b74-d69e551c4f1c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part-1 Data Preprocessing"
      ],
      "metadata": {
        "id": "OuCEL9NGUIPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing the Training Dataset"
      ],
      "metadata": {
        "id": "uNIsEKsgUL25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/training_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kws_GVhkUVWI",
        "outputId": "6a71668d-75ca-48b6-c4a8-cdefe7e93b4f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing the Testing Dataset"
      ],
      "metadata": {
        "id": "5Tilb2dyURaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/dataset/test_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-p5MXjpMxgV",
        "outputId": "5111c499-6e16-45d6-eafe-b8a96b86f511"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2 - Building the CNN"
      ],
      "metadata": {
        "id": "GXtOBc7bZLej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize the CNN"
      ],
      "metadata": {
        "id": "RnqlAmmjZS7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "iED3ZVCkZLK_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1 - Concolution"
      ],
      "metadata": {
        "id": "U4kTm6fsZa5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(64, 64, 3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGeZG1Q1ZZ24",
        "outputId": "9c5b778c-fe10-4413-989e-518e867b864c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2 - Pooling"
      ],
      "metadata": {
        "id": "-I27recrZyU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "aVPK16lhZ1AM"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding a second Convolutional layer"
      ],
      "metadata": {
        "id": "9DQ6Gu8taAXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "76fx6JrQaEaU"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3 - Flattening"
      ],
      "metadata": {
        "id": "W0MHNxpEaJxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "n_6AvlWCaE1h"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 4 - Full Connection"
      ],
      "metadata": {
        "id": "KhdZcNwxaTGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ],
      "metadata": {
        "id": "0BssgAM0aW3r"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 5 - Output Layer"
      ],
      "metadata": {
        "id": "YKAVvkG7acwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "gmXlkyRUaftC"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 3 - Training the CNN"
      ],
      "metadata": {
        "id": "etn8Iuwda8cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Compiling the CNN"
      ],
      "metadata": {
        "id": "ihXYYOpXbTb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "imtbE6eXdFab"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training the CNN on the training dataset and evaluating on test dataset"
      ],
      "metadata": {
        "id": "hqzdYkCkbVb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x= train_set, validation_data= test_set, epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzESmVITdUeu",
        "outputId": "4c6115ef-b217-4622-8fec-6d49f5f16bc7"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 184ms/step - accuracy: 0.5673 - loss: 0.6840 - val_accuracy: 0.6800 - val_loss: 0.5923\n",
            "Epoch 2/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 179ms/step - accuracy: 0.6751 - loss: 0.5893 - val_accuracy: 0.7145 - val_loss: 0.5601\n",
            "Epoch 3/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 193ms/step - accuracy: 0.7140 - loss: 0.5577 - val_accuracy: 0.7205 - val_loss: 0.5774\n",
            "Epoch 4/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 180ms/step - accuracy: 0.7306 - loss: 0.5325 - val_accuracy: 0.7585 - val_loss: 0.4976\n",
            "Epoch 5/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 180ms/step - accuracy: 0.7444 - loss: 0.5088 - val_accuracy: 0.7685 - val_loss: 0.4929\n",
            "Epoch 6/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 177ms/step - accuracy: 0.7516 - loss: 0.5015 - val_accuracy: 0.7545 - val_loss: 0.5030\n",
            "Epoch 7/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 193ms/step - accuracy: 0.7859 - loss: 0.4680 - val_accuracy: 0.7835 - val_loss: 0.4760\n",
            "Epoch 8/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 178ms/step - accuracy: 0.7736 - loss: 0.4631 - val_accuracy: 0.7555 - val_loss: 0.5142\n",
            "Epoch 9/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 179ms/step - accuracy: 0.7889 - loss: 0.4451 - val_accuracy: 0.7690 - val_loss: 0.4811\n",
            "Epoch 10/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 176ms/step - accuracy: 0.7921 - loss: 0.4321 - val_accuracy: 0.7945 - val_loss: 0.4735\n",
            "Epoch 11/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 177ms/step - accuracy: 0.8147 - loss: 0.4076 - val_accuracy: 0.7605 - val_loss: 0.4994\n",
            "Epoch 12/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 177ms/step - accuracy: 0.8203 - loss: 0.3922 - val_accuracy: 0.7610 - val_loss: 0.5377\n",
            "Epoch 13/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 178ms/step - accuracy: 0.8201 - loss: 0.3917 - val_accuracy: 0.7710 - val_loss: 0.5372\n",
            "Epoch 14/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 191ms/step - accuracy: 0.8293 - loss: 0.3767 - val_accuracy: 0.7975 - val_loss: 0.4587\n",
            "Epoch 15/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 177ms/step - accuracy: 0.8352 - loss: 0.3557 - val_accuracy: 0.8050 - val_loss: 0.4557\n",
            "Epoch 16/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 182ms/step - accuracy: 0.8550 - loss: 0.3238 - val_accuracy: 0.8125 - val_loss: 0.4622\n",
            "Epoch 17/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 179ms/step - accuracy: 0.8576 - loss: 0.3261 - val_accuracy: 0.8140 - val_loss: 0.4684\n",
            "Epoch 18/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 185ms/step - accuracy: 0.8587 - loss: 0.3183 - val_accuracy: 0.7960 - val_loss: 0.4777\n",
            "Epoch 19/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 182ms/step - accuracy: 0.8712 - loss: 0.3016 - val_accuracy: 0.7970 - val_loss: 0.5046\n",
            "Epoch 20/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 180ms/step - accuracy: 0.8755 - loss: 0.2903 - val_accuracy: 0.7880 - val_loss: 0.5419\n",
            "Epoch 21/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 182ms/step - accuracy: 0.8830 - loss: 0.2745 - val_accuracy: 0.7940 - val_loss: 0.5144\n",
            "Epoch 22/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 182ms/step - accuracy: 0.8903 - loss: 0.2599 - val_accuracy: 0.7745 - val_loss: 0.5854\n",
            "Epoch 23/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 181ms/step - accuracy: 0.8912 - loss: 0.2556 - val_accuracy: 0.8030 - val_loss: 0.5513\n",
            "Epoch 24/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 178ms/step - accuracy: 0.8999 - loss: 0.2405 - val_accuracy: 0.8000 - val_loss: 0.5190\n",
            "Epoch 25/25\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 179ms/step - accuracy: 0.9074 - loss: 0.2225 - val_accuracy: 0.8060 - val_loss: 0.5453\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78ea50136cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4 - Making a single Prediction"
      ],
      "metadata": {
        "id": "pDsh-7j5dgq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/cat-world.webp', target_size=[64, 64])\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = test_image / 255.0\n",
        "test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "result = cnn.predict(test_image)\n",
        "\n",
        "train_set.class_indices\n",
        "\n",
        "print(train_set.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPZ_eEmAa_bh",
        "outputId": "4cc08de3-f137-456c-8717-bce54eb4da45"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "{'cats': 0, 'dogs': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if result[0][0] > 0.5:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n",
        "print(\"Prediction:\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiJ2grB-ht16",
        "outputId": "0042aa20-8458-43f4-defa-c58be111356e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u3AIEUxnfoV",
        "outputId": "46327055-48d1-4973-d11a-655b23afcd1e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.2855721)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W5eIUdGroHlc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}